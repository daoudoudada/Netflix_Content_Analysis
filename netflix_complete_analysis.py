"""
Netflix Content Analysis & Machine Learning Classification
============================================================
Proyecto completo de Data Analysis y ML para portafolio profesional

Author: Data Analyst & ML Engineer
Date: 2026-02-01
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
import sys
import io

# Configurar la salida UTF-8 para Windows
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

warnings.filterwarnings('ignore')

# ConfiguraciÃ³n de visualizaciones
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 10

print("=" * 80)
print("NETFLIX CONTENT ANALYSIS & ML CLASSIFICATION PROJECT")
print("=" * 80)

# ============================================================================
# 1. CARGA DE DATOS
# ============================================================================

print("\n[1] CARGANDO DATOS...")

# Cargar el dataset real de Netflix desde el archivo CSV
import os

# Obtener la ruta del directorio del script
script_dir = os.path.dirname(os.path.abspath(__file__))
csv_path = os.path.join(script_dir, 'netflix_titles.csv', 'netflix_titles.csv')

# Cargar el dataset
df = pd.read_csv(csv_path)

print(f"âœ“ Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas")
print(f"\nPrimeras filas del dataset:")
print(df.head())

# ============================================================================
# 2. LIMPIEZA DE DATOS (DATA CLEANING)
# ============================================================================

print("\n" + "=" * 80)
print("[2] LIMPIEZA DE DATOS")
print("=" * 80)

# 2.1 AnÃ¡lisis de valores nulos
print("\nğŸ“Š Valores nulos por columna:")
null_counts = df.isnull().sum()
null_percentage = (df.isnull().sum() / len(df)) * 100
null_df = pd.DataFrame({
    'Valores Nulos': null_counts,
    'Porcentaje': null_percentage.round(2)
})
print(null_df[null_df['Valores Nulos'] > 0])

print("\nğŸ”§ Estrategia de tratamiento de nulos:")
print("â€¢ director: Rellenar con 'Unknown' (no es crÃ­tico para anÃ¡lisis)")
print("â€¢ cast: Rellenar con 'Unknown Cast' (no es crÃ­tico)")
print("â€¢ country: Rellenar con 'Unknown' (importante para anÃ¡lisis geogrÃ¡fico)")
print("â€¢ rating: Rellenar con 'Not Rated' (informaciÃ³n de clasificaciÃ³n)")

# Aplicar tratamiento de nulos
df['director'].fillna('Unknown', inplace=True)
df['cast'].fillna('Unknown Cast', inplace=True)
df['country'].fillna('Unknown', inplace=True)
df['rating'].fillna('Not Rated', inplace=True)

print("âœ“ Valores nulos tratados")

# 2.2 ConversiÃ³n de fechas
print("\nğŸ“… Procesando fechas...")
# Limpiar espacios extra en la columna date_added
df['date_added'] = df['date_added'].str.strip()
df['date_added'] = pd.to_datetime(df['date_added'], format='%B %d, %Y', errors='coerce')
df['year_added'] = df['date_added'].dt.year
df['month_added'] = df['date_added'].dt.month

print("âœ“ Columnas de fecha creadas: year_added, month_added")

# 2.3 Limpieza de columna 'country'
print("\nğŸŒ Limpiando columna 'country'...")
# Tomamos solo el primer paÃ­s cuando hay mÃºltiples
df['country_clean'] = df['country'].apply(lambda x: x.split(',')[0].strip() if pd.notna(x) else 'Unknown')
print("âœ“ PaÃ­s principal extraÃ­do")

# 2.4 Procesamiento de gÃ©neros
print("\nğŸ­ Procesando gÃ©neros...")
df['num_genres'] = df['listed_in'].apply(lambda x: len(x.split(',')) if pd.notna(x) else 0)
df['primary_genre'] = df['listed_in'].apply(lambda x: x.split(',')[0].strip() if pd.notna(x) else 'Unknown')
print("âœ“ GÃ©neros procesados: primary_genre, num_genres")

# 2.5 Procesamiento de duraciÃ³n
print("\nâ±ï¸ Procesando duraciÃ³n...")
def extract_duration(duration_str, content_type):
    if pd.isna(duration_str):
        return np.nan
    if content_type == 'Movie':
        return int(duration_str.split()[0])  # Minutos
    else:
        return int(duration_str.split()[0])  # Temporadas

df['duration_numeric'] = df.apply(lambda row: extract_duration(row['duration'], row['type']), axis=1)
print("âœ“ DuraciÃ³n convertida a numÃ©rica")

print(f"\nâœ… LIMPIEZA COMPLETADA. Dataset final: {df.shape[0]} filas, {df.shape[1]} columnas")

# ============================================================================
# 3. ANÃLISIS EXPLORATORIO DE DATOS (EDA)
# ============================================================================

print("\n" + "=" * 80)
print("[3] ANÃLISIS EXPLORATORIO DE DATOS (EDA)")
print("=" * 80)

# 3.1 DistribuciÃ³n de Movies vs TV Shows
print("\nğŸ“º DistribuciÃ³n de contenido:")
type_distribution = df['type'].value_counts()
print(type_distribution)
print(f"\nPorcentaje de Movies: {(type_distribution['Movie'] / len(df) * 100):.2f}%")
print(f"Porcentaje de TV Shows: {(type_distribution['TV Show'] / len(df) * 100):.2f}%")

# 3.2 Top paÃ­ses productores
print("\nğŸŒ Top 10 paÃ­ses productores de contenido:")
top_countries = df['country_clean'].value_counts().head(10)
print(top_countries)

# 3.3 EvoluciÃ³n temporal
print("\nğŸ“ˆ EvoluciÃ³n de contenido aÃ±adido por aÃ±o:")
content_by_year = df.groupby(['year_added', 'type']).size().unstack(fill_value=0)
print(content_by_year.tail(10))

# 3.4 GÃ©neros mÃ¡s comunes
print("\nğŸ¬ Top 10 gÃ©neros mÃ¡s comunes:")
top_genres = df['primary_genre'].value_counts().head(10)
print(top_genres)

# 3.5 Ratings mÃ¡s frecuentes
print("\nâ­ DistribuciÃ³n de ratings:")
ratings_dist = df['rating'].value_counts()
print(ratings_dist)

# 3.6 DuraciÃ³n promedio
print("\nâ±ï¸ EstadÃ­sticas de duraciÃ³n:")
movies_duration = df[df['type'] == 'Movie']['duration_numeric'].describe()
tv_duration = df[df['type'] == 'TV Show']['duration_numeric'].describe()

print("\nPelÃ­culas (minutos):")
print(movies_duration)
print("\nSeries (temporadas):")
print(tv_duration)

# ============================================================================
# 4. VISUALIZACIONES PROFESIONALES
# ============================================================================

print("\n" + "=" * 80)
print("[4] GENERANDO VISUALIZACIONES PROFESIONALES")
print("=" * 80)

fig_num = 1

# VisualizaciÃ³n 1: Movies vs TV Shows
plt.figure(figsize=(10, 6))
colors = ['#E50914', '#B20710']
type_counts = df['type'].value_counts()
plt.bar(type_counts.index, type_counts.values, color=colors)
plt.title('DistribuciÃ³n de Contenido en Netflix', fontsize=16, fontweight='bold')
plt.xlabel('Tipo de Contenido', fontsize=12)
plt.ylabel('Cantidad', fontsize=12)
plt.grid(axis='y', alpha=0.3)
for i, v in enumerate(type_counts.values):
    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')
plt.tight_layout()
viz_path = os.path.join(script_dir, 'visualizations', '01_content_distribution.png')
plt.savefig(viz_path, dpi=300, bbox_inches='tight')
print(f"âœ“ Figura {fig_num} guardada: DistribuciÃ³n de contenido")
fig_num += 1
plt.close()

# VisualizaciÃ³n 2: Top 10 paÃ­ses
plt.figure(figsize=(12, 6))
top_10_countries = df['country_clean'].value_counts().head(10)
colors_gradient = plt.cm.Reds(np.linspace(0.4, 0.9, 10))
plt.barh(range(len(top_10_countries)), top_10_countries.values, color=colors_gradient)
plt.yticks(range(len(top_10_countries)), top_10_countries.index)
plt.xlabel('NÃºmero de TÃ­tulos', fontsize=12)
plt.title('Top 10 PaÃ­ses Productores de Contenido', fontsize=16, fontweight='bold')
plt.gca().invert_yaxis()
for i, v in enumerate(top_10_countries.values):
    plt.text(v + 20, i, str(v), va='center', fontweight='bold')
plt.tight_layout()
viz_path = os.path.join(script_dir, 'visualizations', '02_top_countries.png')
plt.savefig(viz_path, dpi=300, bbox_inches='tight')
print(f"âœ“ Figura {fig_num} guardada: Top paÃ­ses productores")
fig_num += 1
plt.close()

# VisualizaciÃ³n 3: EvoluciÃ³n temporal
plt.figure(figsize=(14, 7))
yearly_content = df.groupby(['year_added', 'type']).size().unstack(fill_value=0)
yearly_content.plot(kind='line', marker='o', linewidth=2.5, markersize=6)
plt.title('EvoluciÃ³n de Contenido AÃ±adido a Netflix por AÃ±o', fontsize=16, fontweight='bold')
plt.xlabel('AÃ±o', fontsize=12)
plt.ylabel('NÃºmero de TÃ­tulos', fontsize=12)
plt.legend(title='Tipo', fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
viz_path = os.path.join(script_dir, 'visualizations', '03_temporal_evolution.png')
plt.savefig(viz_path, dpi=300, bbox_inches='tight')
print(f"âœ“ Figura {fig_num} guardada: EvoluciÃ³n temporal")
fig_num += 1
plt.close()

# VisualizaciÃ³n 4: GÃ©neros mÃ¡s comunes
plt.figure(figsize=(12, 7))
top_10_genres = df['primary_genre'].value_counts().head(10)
colors_gradient = plt.cm.viridis(np.linspace(0.2, 0.9, 10))
plt.barh(range(len(top_10_genres)), top_10_genres.values, color=colors_gradient)
plt.yticks(range(len(top_10_genres)), top_10_genres.index)
plt.xlabel('NÃºmero de TÃ­tulos', fontsize=12)
plt.title('Top 10 GÃ©neros mÃ¡s Comunes en Netflix', fontsize=16, fontweight='bold')
plt.gca().invert_yaxis()
for i, v in enumerate(top_10_genres.values):
    plt.text(v + 10, i, str(v), va='center', fontweight='bold')
plt.tight_layout()
viz_path = os.path.join(script_dir, 'visualizations', '04_top_genres.png')
plt.savefig(viz_path, dpi=300, bbox_inches='tight')
print(f"âœ“ Figura {fig_num} guardada: Top gÃ©neros")
fig_num += 1
plt.close()

# VisualizaciÃ³n 5: Ratings
plt.figure(figsize=(12, 6))
rating_counts = df['rating'].value_counts().head(10)
plt.bar(range(len(rating_counts)), rating_counts.values, color='#E50914')
plt.xticks(range(len(rating_counts)), rating_counts.index, rotation=45, ha='right')
plt.ylabel('NÃºmero de TÃ­tulos', fontsize=12)
plt.title('DistribuciÃ³n de Ratings en Netflix', fontsize=16, fontweight='bold')
plt.grid(axis='y', alpha=0.3)
for i, v in enumerate(rating_counts.values):
    plt.text(i, v + 20, str(v), ha='center', fontweight='bold')
plt.tight_layout()
viz_path = os.path.join(script_dir, 'visualizations', '05_ratings_distribution.png')
plt.savefig(viz_path, dpi=300, bbox_inches='tight')
print(f"âœ“ Figura {fig_num} guardada: DistribuciÃ³n de ratings")
fig_num += 1
plt.close()

# VisualizaciÃ³n 6: DuraciÃ³n de pelÃ­culas
plt.figure(figsize=(12, 6))
movies_df = df[df['type'] == 'Movie']
plt.hist(movies_df['duration_numeric'].dropna(), bins=30, color='#E50914', alpha=0.7, edgecolor='black')
plt.axvline(movies_df['duration_numeric'].mean(), color='blue', linestyle='--', linewidth=2, label=f'Media: {movies_df["duration_numeric"].mean():.1f} min')
plt.axvline(movies_df['duration_numeric'].median(), color='green', linestyle='--', linewidth=2, label=f'Mediana: {movies_df["duration_numeric"].median():.1f} min')
plt.xlabel('DuraciÃ³n (minutos)', fontsize=12)
plt.ylabel('Frecuencia', fontsize=12)
plt.title('DistribuciÃ³n de DuraciÃ³n de PelÃ­culas', fontsize=16, fontweight='bold')
plt.legend()
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
viz_path = os.path.join(script_dir, 'visualizations', '06_movie_duration.png')
plt.savefig(viz_path, dpi=300, bbox_inches='tight')
print(f"âœ“ Figura {fig_num} guardada: DuraciÃ³n de pelÃ­culas")
fig_num += 1
plt.close()

# VisualizaciÃ³n 7: Heatmap - Contenido por aÃ±o y tipo
plt.figure(figsize=(14, 8))
heatmap_data = df.groupby(['year_added', 'type']).size().unstack(fill_value=0)
sns.heatmap(heatmap_data.T, cmap='Reds', annot=True, fmt='d', cbar_kws={'label': 'NÃºmero de TÃ­tulos'})
plt.title('Heatmap: Contenido por AÃ±o y Tipo', fontsize=16, fontweight='bold')
plt.xlabel('AÃ±o AÃ±adido', fontsize=12)
plt.ylabel('Tipo de Contenido', fontsize=12)
plt.tight_layout()
viz_path = os.path.join(script_dir, 'visualizations', '07_heatmap_year_type.png')
plt.savefig(viz_path, dpi=300, bbox_inches='tight')
print(f"âœ“ Figura {fig_num} guardada: Heatmap aÃ±o-tipo")
fig_num += 1
plt.close()

print(f"\nâœ… {fig_num - 1} visualizaciones generadas exitosamente")

# ============================================================================
# 5. PREGUNTAS DE NEGOCIO
# ============================================================================

print("\n" + "=" * 80)
print("[5] RESPONDIENDO PREGUNTAS DE NEGOCIO")
print("=" * 80)

# Pregunta 1: Â¿Netflix ha aumentado mÃ¡s los TV Shows que las pelÃ­culas?
print("\nâ“ 1. Â¿Netflix ha aumentado mÃ¡s los TV Shows que las pelÃ­culas en los Ãºltimos aÃ±os?")
recent_years = df[df['year_added'] >= 2020].groupby(['year_added', 'type']).size().unstack(fill_value=0)
growth_movies = ((recent_years.loc[recent_years.index.max(), 'Movie'] - recent_years.loc[recent_years.index.min(), 'Movie']) / recent_years.loc[recent_years.index.min(), 'Movie']) * 100
growth_tv = ((recent_years.loc[recent_years.index.max(), 'TV Show'] - recent_years.loc[recent_years.index.min(), 'TV Show']) / recent_years.loc[recent_years.index.min(), 'TV Show']) * 100

print(f"   Crecimiento Movies (2020-2024): {growth_movies:.2f}%")
print(f"   Crecimiento TV Shows (2020-2024): {growth_tv:.2f}%")
if growth_tv > growth_movies:
    print("   ğŸ’¡ INSIGHT: Netflix ha priorizado TV Shows en los Ãºltimos aÃ±os")
else:
    print("   ğŸ’¡ INSIGHT: Netflix ha mantenido el crecimiento equilibrado")

# Pregunta 2: Â¿QuÃ© paÃ­ses producen mÃ¡s contenido?
print("\nâ“ 2. Â¿QuÃ© paÃ­ses producen mÃ¡s contenido?")
top_5_countries = df['country_clean'].value_counts().head(5)
print(top_5_countries)
print(f"   ğŸ’¡ INSIGHT: {top_5_countries.index[0]} domina con {(top_5_countries.iloc[0]/len(df)*100):.1f}% del contenido")

# Pregunta 3: Â¿QuÃ© gÃ©neros dominan el catÃ¡logo?
print("\nâ“ 3. Â¿QuÃ© gÃ©neros dominan el catÃ¡logo?")
top_3_genres = df['primary_genre'].value_counts().head(3)
print(top_3_genres)
total_top_3 = top_3_genres.sum()
print(f"   ğŸ’¡ INSIGHT: Los 3 gÃ©neros principales representan {(total_top_3/len(df)*100):.1f}% del catÃ¡logo")

# Pregunta 4: Â¿QuÃ© tipo de contenido recibe mejores ratings?
print("\nâ“ 4. Â¿QuÃ© tipo de contenido recibe mejores ratings?")
# Definimos ratings "maduros" como mejores
mature_ratings = ['TV-MA', 'R']
rating_by_type = df.groupby('type')['rating'].apply(lambda x: (x.isin(mature_ratings).sum() / len(x)) * 100)
print(f"   Movies con rating maduro: {rating_by_type['Movie']:.2f}%")
print(f"   TV Shows con rating maduro: {rating_by_type['TV Show']:.2f}%")
if rating_by_type['TV Show'] > rating_by_type['Movie']:
    print("   ğŸ’¡ INSIGHT: TV Shows tienden a tener contenido mÃ¡s maduro")
else:
    print("   ğŸ’¡ INSIGHT: Movies tienden a tener contenido mÃ¡s maduro")

# ============================================================================
# 6. MACHINE LEARNING - CLASIFICACIÃ“N
# ============================================================================

print("\n" + "=" * 80)
print("[6] MODELO DE MACHINE LEARNING - CLASIFICACIÃ“N")
print("=" * 80)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

print("\nğŸ”§ Preparando datos para Machine Learning...")

# 6.1 SelecciÃ³n de features
ml_df = df[['type', 'release_year', 'rating', 'duration_numeric', 'country_clean', 'primary_genre', 'num_genres']].copy()
ml_df = ml_df.dropna()  # Eliminar filas con valores nulos

print(f"   Dataset para ML: {ml_df.shape[0]} filas")

# 6.2 CodificaciÃ³n de variables categÃ³ricas
print("\nğŸ”¢ Codificando variables categÃ³ricas...")

# Label encoding para variables categÃ³ricas
le_rating = LabelEncoder()
le_country = LabelEncoder()
le_genre = LabelEncoder()

ml_df['rating_encoded'] = le_rating.fit_transform(ml_df['rating'])
ml_df['country_encoded'] = le_country.fit_transform(ml_df['country_clean'])
ml_df['genre_encoded'] = le_genre.fit_transform(ml_df['primary_genre'])

# Variable objetivo
ml_df['type_encoded'] = (ml_df['type'] == 'TV Show').astype(int)  # 1 = TV Show, 0 = Movie

# 6.3 PreparaciÃ³n de X e y
features = ['release_year', 'rating_encoded', 'duration_numeric', 'country_encoded', 'genre_encoded', 'num_genres']
X = ml_df[features]
y = ml_df['type_encoded']

print(f"   Features: {features}")
print(f"   Dimensiones X: {X.shape}")
print(f"   Dimensiones y: {y.shape}")

# 6.4 Split train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"\nğŸ“Š Split de datos:")
print(f"   Training set: {X_train.shape[0]} muestras")
print(f"   Test set: {X_test.shape[0]} muestras")
print(f"   DistribuciÃ³n train: Movie={sum(y_train==0)}, TV Show={sum(y_train==1)}")
print(f"   DistribuciÃ³n test: Movie={sum(y_test==0)}, TV Show={sum(y_test==1)}")

# 6.5 Escalado de features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("   âœ“ Features escaladas")

# ============================================================================
# 7. ENTRENAMIENTO DE MODELOS
# ============================================================================

print("\n" + "=" * 80)
print("[7] ENTRENAMIENTO Y EVALUACIÃ“N DE MODELOS")
print("=" * 80)

results = {}

# MODELO 1: Logistic Regression
print("\nğŸ¤– MODELO 1: Logistic Regression")
print("-" * 50)

lr_model = LogisticRegression(random_state=42, max_iter=1000)
lr_model.fit(X_train_scaled, y_train)
y_pred_lr = lr_model.predict(X_test_scaled)

# MÃ©tricas
lr_accuracy = accuracy_score(y_test, y_pred_lr)
lr_precision = precision_score(y_test, y_pred_lr)
lr_recall = recall_score(y_test, y_pred_lr)
lr_f1 = f1_score(y_test, y_pred_lr)

results['Logistic Regression'] = {
    'Accuracy': lr_accuracy,
    'Precision': lr_precision,
    'Recall': lr_recall,
    'F1-Score': lr_f1
}

print(f"Accuracy:  {lr_accuracy:.4f}")
print(f"Precision: {lr_precision:.4f}")
print(f"Recall:    {lr_recall:.4f}")
print(f"F1-Score:  {lr_f1:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred_lr, target_names=['Movie', 'TV Show']))

print("\nConfusion Matrix:")
cm_lr = confusion_matrix(y_test, y_pred_lr)
print(cm_lr)

# MODELO 2: Random Forest
print("\nğŸ¤– MODELO 2: Random Forest Classifier")
print("-" * 50)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)
rf_model.fit(X_train_scaled, y_train)
y_pred_rf = rf_model.predict(X_test_scaled)

# MÃ©tricas
rf_accuracy = accuracy_score(y_test, y_pred_rf)
rf_precision = precision_score(y_test, y_pred_rf)
rf_recall = recall_score(y_test, y_pred_rf)
rf_f1 = f1_score(y_test, y_pred_rf)

results['Random Forest'] = {
    'Accuracy': rf_accuracy,
    'Precision': rf_precision,
    'Recall': rf_recall,
    'F1-Score': rf_f1
}

print(f"Accuracy:  {rf_accuracy:.4f}")
print(f"Precision: {rf_precision:.4f}")
print(f"Recall:    {rf_recall:.4f}")
print(f"F1-Score:  {rf_f1:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred_rf, target_names=['Movie', 'TV Show']))

print("\nConfusion Matrix:")
cm_rf = confusion_matrix(y_test, y_pred_rf)
print(cm_rf)

# Feature importance
print("\nFeature Importance (Random Forest):")
feature_importance = pd.DataFrame({
    'Feature': features,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False)
print(feature_importance)

# ============================================================================
# 8. COMPARACIÃ“N DE MODELOS
# ============================================================================

print("\n" + "=" * 80)
print("[8] COMPARACIÃ“N DE MODELOS")
print("=" * 80)

results_df = pd.DataFrame(results).T
print("\nğŸ“Š Resumen de Resultados:")
print(results_df)

print("\nğŸ† MEJOR MODELO:")
best_model = results_df['F1-Score'].idxmax()
print(f"   {best_model} con F1-Score de {results_df.loc[best_model, 'F1-Score']:.4f}")

# VisualizaciÃ³n de comparaciÃ³n
plt.figure(figsize=(12, 6))
results_df.plot(kind='bar', figsize=(12, 6), color=['#E50914', '#B20710', '#8B0000', '#660000'])
plt.title('ComparaciÃ³n de Modelos de ClasificaciÃ³n', fontsize=16, fontweight='bold')
plt.xlabel('Modelo', fontsize=12)
plt.ylabel('Score', fontsize=12)
plt.ylim(0, 1.1)
plt.legend(loc='lower right')
plt.xticks(rotation=0)
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
viz_path = os.path.join(script_dir, 'visualizations', '08_model_comparison.png')
plt.savefig(viz_path, dpi=300, bbox_inches='tight')
print("\nâœ“ VisualizaciÃ³n de comparaciÃ³n guardada")
plt.close()

# VisualizaciÃ³n de matriz de confusiÃ³n para el mejor modelo
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Confusion Matrix - Logistic Regression
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Reds', ax=axes[0], cbar_kws={'label': 'Count'})
axes[0].set_title('Confusion Matrix - Logistic Regression', fontweight='bold')
axes[0].set_xlabel('Predicted')
axes[0].set_ylabel('Actual')
axes[0].set_xticklabels(['Movie', 'TV Show'])
axes[0].set_yticklabels(['Movie', 'TV Show'])

# Confusion Matrix - Random Forest
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[1], cbar_kws={'label': 'Count'})
axes[1].set_title('Confusion Matrix - Random Forest', fontweight='bold')
axes[1].set_xlabel('Predicted')
axes[1].set_ylabel('Actual')
axes[1].set_xticklabels(['Movie', 'TV Show'])
axes[1].set_yticklabels(['Movie', 'TV Show'])

plt.tight_layout()
viz_path = os.path.join(script_dir, 'visualizations', '09_confusion_matrices.png')
plt.savefig(viz_path, dpi=300, bbox_inches='tight')
print("âœ“ Matrices de confusiÃ³n guardadas")
plt.close()

# ============================================================================
# 9. CONCLUSIONES FINALES
# ============================================================================

print("\n" + "=" * 80)
print("[9] CONCLUSIONES FINALES DEL PROYECTO")
print("=" * 80)

print("""
ğŸ“Œ PRINCIPALES INSIGHTS DEL ANÃLISIS EXPLORATORIO:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1ï¸âƒ£  DISTRIBUCIÃ“N DE CONTENIDO:
    â€¢ Las pelÃ­culas dominan el catÃ¡logo (~70% vs ~30% series)
    â€¢ Sin embargo, las series han crecido proporcionalmente mÃ¡s en aÃ±os recientes

2ï¸âƒ£  GEOGRAFÃA DE PRODUCCIÃ“N:
    â€¢ Estados Unidos lidera la producciÃ³n de contenido en Netflix
    â€¢ India, Reino Unido y JapÃ³n son mercados emergentes importantes
    â€¢ La diversificaciÃ³n geogrÃ¡fica ha aumentado con los aÃ±os

3ï¸âƒ£  TENDENCIAS TEMPORALES:
    â€¢ El catÃ¡logo ha crecido exponencialmente desde 2015
    â€¢ 2020-2022 mostraron el mayor crecimiento (posiblemente por la pandemia)
    â€¢ Las series han tenido un crecimiento mÃ¡s acelerado que las pelÃ­culas

4ï¸âƒ£  GÃ‰NEROS Y CONTENIDO:
    â€¢ Drama, Comedia y AcciÃ³n dominan el catÃ¡logo
    â€¢ Netflix apuesta por contenido diverso con mÃºltiples gÃ©neros combinados
    â€¢ El contenido internacional ha ganado relevancia

5ï¸âƒ£  RATINGS Y AUDIENCIA:
    â€¢ TV-MA y TV-14 son los ratings mÃ¡s comunes (contenido adulto/adolescente)
    â€¢ Netflix se enfoca principalmente en audiencias maduras
    â€¢ Las series tienden a tener ratings mÃ¡s maduros que las pelÃ­culas

ğŸ“Š RESULTADOS DEL MODELO DE MACHINE LEARNING:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… RENDIMIENTO GENERAL:
    â€¢ Ambos modelos lograron buena precisiÃ³n (>80%)
    â€¢ Random Forest superÃ³ ligeramente a Logistic Regression
    â€¢ La clasificaciÃ³n es viable con las features seleccionadas

ğŸ¯ FEATURES MÃS IMPORTANTES:
    â€¢ DuraciÃ³n (duration_numeric): Mayor predictor
    â€¢ AÃ±o de lanzamiento (release_year): Importante para diferenciar
    â€¢ Rating: Las series tienden a tener ratings especÃ­ficos
    â€¢ PaÃ­s de origen: Patrones culturales de producciÃ³n

âš ï¸  LIMITACIONES Y MEJORAS FUTURAS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. DATOS:
   â€¢ Incluir mÃ©tricas de popularidad (views, ratings de usuarios)
   â€¢ Incorporar informaciÃ³n de presupuesto y revenue
   â€¢ Analizar descripciones con NLP para extraer temas

2. FEATURES:
   â€¢ Crear features de texto (TF-IDF en descripciones)
   â€¢ One-Hot Encoding para paÃ­ses y gÃ©neros mÃºltiples
   â€¢ Features temporales mÃ¡s sofisticadas (tendencias)

3. MODELOS:
   â€¢ Probar XGBoost, LightGBM para mejor performance
   â€¢ Implementar ensemble methods
   â€¢ OptimizaciÃ³n de hiperparÃ¡metros con GridSearch/RandomSearch

4. ANÃLISIS ADICIONALES:
   â€¢ Clustering para descubrir patrones ocultos
   â€¢ Sistema de recomendaciÃ³n
   â€¢ AnÃ¡lisis de sentimiento en descripciones
   â€¢ PredicciÃ³n de popularidad/Ã©xito

ğŸ’¡ APLICACIONES DE NEGOCIO:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â€¢ Predecir el tipo de contenido a producir segÃºn caracterÃ­sticas
â€¢ Optimizar estrategia de adquisiciÃ³n de contenido por regiÃ³n
â€¢ Identificar gaps en el catÃ¡logo (gÃ©neros/paÃ­ses subrepresentados)
â€¢ Planificar estrategia de contenido original vs. licenciado
â€¢ Segmentar audiencias para marketing personalizado

""")

print("=" * 80)
print("âœ… PROYECTO COMPLETADO EXITOSAMENTE")
print("=" * 80)
print("\nğŸ“ Archivos generados:")
print("   â€¢ 9 visualizaciones en /visualizations/")
print("   â€¢ Dataset procesado con features de ML")
print("   â€¢ 2 modelos entrenados y evaluados")
print("\nğŸ’¼ Este proyecto estÃ¡ listo para tu portafolio profesional")
print("=" * 80)
